<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <meta name="keywords" content="Tokamak Disruption Simulation, TDS">
        <meta name="google-site-verification" content="45K56TawSdzbgy-uDtfJdYwp7zaVdL3fIAGYt869wwU" />
<!--	<title></title>  -->
        <title>TDS - Tokamak Disruption Simulation SciDAC</title>

        <link href="../css/bootstrap-mfem.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="../css/highlight.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        
    </head>

    <body>
        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="https://tds-scidac.github.io">TDS</a>
        </div>

        <script>var base_url = '..';</script>
        <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            
            
            
            
            
                <li >
                    <!-- Replace "nav_item.url|url" with "nav_item.url" for older mkdocs (before 1.0) -->
                    <a href="../news/">News</a>
                </li>
            
            
            
            
            
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Physics <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
                            <li >
                                 <a href="../cont-fmr/">Control & flux surface destruction</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../pixie3d/">Nonlinear MHD leading into disruption</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../gts/">Thermal quench of core plasmas</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../bout/">Thermal quench of edge/boundary plasmas</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../TQ-VPIC/">Parallel transport physics of plasma thermal quench</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../cr/">Collisional-radiative modeling of disrupting plasma</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../sheath/">Kinetic modeling of plasma-wall and plasma-neutral interaction</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../drekar/">Multifluid modeling of plasma/neutral interaction and VDE</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../RAMc/">Integrated runaway modeling for current quench</a>
                            </li>
                        
                    
                    </ul>
                </li>
            
            
            
            
            
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Computing <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
                            <li >
                                 <a href="../anisotropic/">Algorithmic innovation for anisotropic transport</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../mfem/">MFEM-based implicit MHD solver with AMR</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../fokkerplanck/">PETSc-p4est relativistic Fokker-Planck-Boltzmann solver</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../hdg/">Scalable hybridized DG and exponential DG for fluid models</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../uq/">Uncertainty Quantification</a>
                            </li>
                        
                    
                        
                            <li >
                                 <a href="../ml/">Machine Learning</a>
                            </li>
                        
                    
                    </ul>
                </li>
            
            
            
            
            
                <li >
                    <!-- Replace "nav_item.url|url" with "nav_item.url" for older mkdocs (before 1.0) -->
                    <a href="../publications/">Publications</a>
                </li>
            
            
            
            
            
                <li >
                    <!-- Replace "nav_item.url|url" with "nav_item.url" for older mkdocs (before 1.0) -->
                    <a href="../gallery/">Gallery</a>
                </li>
            
            
            
            
            
                <li >
                    <!-- Replace "nav_item.url|url" with "nav_item.url" for older mkdocs (before 1.0) -->
                    <a href="../awards/">Awards</a>
                </li>
            
            
            
            
            
                <li >
                    <!-- Replace "nav_item.url|url" with "nav_item.url" for older mkdocs (before 1.0) -->
                    <a href="../about/">About</a>
                </li>
            
            
            
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            
            <div class="col-md-3 visible-xs visible-sm"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#high-performance-parallel-scaling-of-fluid-plasma-simulations-in-drekar">High performance parallel scaling of fluid plasma simulations in Drekar</a></li>
        
            <li><a href="#overview">Overview</a></li>
        
            <li><a href="#scaling-of-multilevel-preconditioners-for-resistive-mhd-based-on-multiphysics-block-preconditioning-preliminary-results">Scaling of Multilevel Preconditioners for resistive MHD based on multiphysics block preconditioning (preliminary results)</a></li>
        
            <li><a href="#scalable-multilfuid-em-solvers-based-on-multiphysics-block-preconditioning">Scalable multilfuid EM solvers based on multiphysics block preconditioning</a></li>
        
    
    </ul>
</div>

<!-- Developer notes:
  See the MkDocs documentation in https://www.mkdocs.org/dev-guide/themes/#page
  and the Jinja2 template API in https://tedboy.github.io/jinja2/index.html
--></div> <!-- toc on top on mobile -->
            <div class="col-md-9" role="main">

<h1 id="high-performance-parallel-scaling-of-fluid-plasma-simulations-in-drekar">High performance parallel scaling of fluid plasma simulations in Drekar</h1>
<p>Sandia National Laboratories + collaborators (LANL, FASTMATH)</p>
<p><strong>SAND2022-3490 W. Approved for public release; distribution is unlimited.</strong> </p>
<h2 id="overview">Overview</h2>
<p>Disruption modeling for characterization, prediction, and mitigation is essential for realizing tokamak
fusion. In TDS, advanced plasma models (extended MHD, &amp; multifluid) are being explored for modeling
electron dynamics, fast reconnection, transport in 3D fields, and strong neutral jet - plasma interactions.
To enable TDS studies, we are applying and extending advanced ASCR scalable algorithms and software
for </p>
<ol>
<li>
<p>Implicit/IMEX extended MHD and multifluid EM plasma formulations with stabilized unstructured FE discretizations as continuum models,</p>
</li>
<li>
<p>Iterative solvers, and optimal physics-based multigrid preconditioners for efficient solution of multiple-time-scale plasma physics systems,</p>
</li>
</ol>
<hr />
<h2 id="scaling-of-multilevel-preconditioners-for-resistive-mhd-based-on-multiphysics-block-preconditioning-preliminary-results">Scaling of Multilevel Preconditioners for resistive MHD based on multiphysics block preconditioning (preliminary results)</h2>
<p>Peter Ohm (SNL), John Shadid (SNL), Edward Phillips (SNL), Ray Tuminaro (SNL),Jonathan Hu (SNL), Jesus Bonilla (LANL), Michael Crockatt (SNL) </p>
<p>A critical component of implicit or IMEX MHD simulations of complex multiphysics systems is the development of scalable preconditioners.
In this context there are two significant issues that must be addressed for implicit solution of these systems.
These are the ill-conditioning of the linear systems that occurs due to the existence of elliptic type operators related to
diffusion type process, and hyperbolic type operators that are often generated from off-diagonal cross-coupled transport mechanisms.
To handle the elliptic type ill-conditioning optimal scalable multilevel methods are employed. For the
cross-coupled multiphysics hyperbolic interactions physics-based (PB) / approximate block preconditioning (ABF) preconditioning approaches
are used. These PB/ABF methods reduce the implicit solve for the complex coupled multifluid system into
a set of sub-systems that segregate the physics (in the preconditioner only) for which we have demonstrated
the use of scalable algebraic multilevel solvers. General details of these approaches can be found in <a href="https://doi.org/10.1016/j.cma.2016.01.019">VMS Incompressible MHD</a>, <a href="https://doi.org/10.1016/j.cam.2017.09.028">Fully-coupled AMG Resistive MHD</a>, <a href="https://doi.org/10.1137/12088879X">ABF 2D Reduced MHD</a>, <a href="https://doi.org/10.1137/15M1017946">Teko PB/ABF Preconditioning Package</a>.</p>
<p>As an initial demonstration of the effectiveness of the PB/ABF approach
to deal withe the off-diagonal coupling of the Alfven wave we show the solution statistics for increasing Alfven wave CFLs
for a preliminary ITER VDE computational after a thermal quench.</p>
<div class="row">
    <div class="col-sm-3"></div>
    <div class="col-sm-6">
        <img src="../img/gallery/drekar/VMS_ResistiveMHD_Alfven_Wave_CFL_Scaling_ABF.png" alt="" width="100%">
    </div>
    <div class="col-sm-3"></div>
</div>
<p><em>The table presents the number of time steps (nT), the average number of nonlinear Newton steps per time step (nL/nT),
the average number of linear iterations per non-linear step (l,nL) and the average time per time step (t/nT) excluding IO.
These preliminary results indicates that the proposed PB/ABF method has excellent algorithmic and time per time step scaling
for increasing Alfven wave CFLs.</em></p>
<h3 id="strong-scaling-of-fully-implicit-vms-resistive-mhd-formulation">Strong scaling of fully implicit VMS resistive MHD formulation</h3>
<p>We now consider a heterogeneous geometry consisting of the plasma region ITER geometry as well as the surrounding solid wall. These figures demonstrate the strong scaling of the implementation for two Lundquist numbers $10^4$, $10^7$.
The simulations use a mesh with 346, 272 elements (7.2K poloidal 48 toroidal) and run to 100 global Alfven times with a constant time-step size dt = 2. This results in a max Alfven wave $CFL_A=750$ and max flow $CFL_u ={3}/{2}$. The number of cores is increased from 72 cores to 4680 cores, a 16x increase. The tests start with around 4800 elements per core with 72 cores, and end with around 300 elements per core with 1152 cores. The strong scaling begins to to become less efficient after approx. 300 elements per core done on 1152 cores. This is to be expected with so little work per core and with increasing cost for communication. The total time to solution, the speedup, efficiency and the iteration count for the solver are all presented. This scaling is excellent for a fully-implicit resistive MHD formulation with 300 elements per processor at the 1152 core case. The linear solver iteration results also demonstrate that the V-cycle coarse grid projection operators and coarse smoothers, and coarse grid solver are working as required as the processor count / sub-domains are increasing. It should be noted that a slightly more expensive smoother was used for the $S=10^7$ case.</p>
<div class="row">
    <div class="col-md-6">
        <img src="../img/gallery/drekar/VDE_Scaling_Time_to_Solution.png" alt="" width="100%">
    </div>
    <div class="col-md-6">
        <img src="../img/gallery/drekar/VDE_Scaling_speedup.png" alt="" width="92%">
    </div>
</div>
<div class="row">
    <div class="col-md-6">
        <img src="../img/gallery/drekar/VDE_Scaling_efficiency.png" alt="" width="100%">
    </div>
    <div class="col-md-6">
        <img src="../img/gallery/drekar/VDE_Scaling_Iteration_count.png" alt="" width="97%">
    </div>
</div>
<p><em>Strong scaling of the VMS unstructured FE low Mach number compressible MHD solver (Drekar) for two Lundquist numbers, $S = 10^4,\ 10^7$. The results show excellent strong scaling and demonstrate that up to as few as 300 elements per processor the fully-implicit formulation scales well for this cold VDE simulation.</em></p>
<h3 id="weak-scaling-of-fully-implicit-vms-resistive-mhd-formulation">Weak scaling of fully implicit VMS resistive MHD formulation</h3>
<p>Next we have weak scaling plotted in this figure. The weak-scaling tests were done with both a Lundquist number $S = 10^4$  and $S = 10^7$. The time-step size was limited by both a max Alfven wave $CFL_A = 400$ and a max flow $CFL_u = 2.0$ resulting in approximate average time-step sizes of 1.2, 0.55, and 0.25 global Alfven times for the respective mesh sizes. The simulation was run to 50 global Alfven times. The smallest mesh contained 346,272 elements (7.2K poloidal 48 toroidal), with 3,876,048 unknowns and was run on 108 cores. The next mesh contained 2,770,176 elements (28.8K poloidal 96 toroidal), with 30,739,104 unknowns and was run on 864 cores. The largest mesh contained 22,161,408 elements (115.2K poloidal 192 toroidal), with 244,842,048 unknowns and was run on 6912 cores. This weak Scaling shows that the very good scaling of the approximate block multiphysics preconditioner and Schur complement approximations Are capturing the required unresolved fast physics.</p>
<div class="row">
    <div class="col-md-1"></div>
    <div class="col-md-10">
        <img src="../img/gallery/drekar/VDE_Weak_scaling.png" alt="" width="90%">
    </div>
    <div class="col-md-1"></div>
</div>
<p><em>Weak scaling of the VMS unstructured FE low Mach number compressible MHD solver (Drekar) for two Lundquist numbers, $S = 10^4,\ 10^7$. The results show excellent week scaling and demonstrate that up to 6912 processors the fully-implicit formulation scales well for this cold VDE simulation.</em></p>
<h3 id="lundquist-number-scaling-of-fully-implicit-vms-resistive-mhd-formulation">Lundquist number scaling of fully implicit VMS resistive MHD formulation</h3>
<p>Finally, the scaling of the iterative solver with respect to the Lundquist number is shown. The time-step size was limited by a max Alfven wave $CFL_A = 400$ and a max flow $CFF_u= 2$, and was run to 25 global Alfven times, resulting in an average time-step size of $dt =1.2$. The mesh has 346,272 elements, and was run on 896 ARM cores. These results indicates that the fully-implicit formulation and approximate block preconditioners are robust with respect to increasing Lundquist numbers over this large $10^8$ increase.</p>
<div class="row">
    <div class="col-md-10">
        <img src="../img/gallery/drekar/Lundquist_number_Scaling.png" alt="" width="90%">
    </div>
    <div class="col-md-1"></div>
</div>
<p><em>Lundquist number scaling of the VMS unstructured FE low Mach number compressible MHD solver (Drekar) for a fixed mesh size. The results show excellent scaling and demonstrate that up to $S=10^{12}$.</em></p>
<hr />
<h2 id="scalable-multilfuid-em-solvers-based-on-multiphysics-block-preconditioning">Scalable multilfuid EM solvers based on multiphysics block preconditioning</h2>
<p>John Shadid (SNL), Edward Phillips (SNL)</p>
<p>A critical component of simulating large-scale multifluid systems is our
physics-based (PB) / approximate block preconditioning (ABF) preconditioning approaches for complex
multiphysics, these methods reduce the implicit solve for the complex coupled multifluid system into
a set of sub-systems that segregate the physics (in the preconditioner only) for which we have demonstrated
the use of scalable algebraic multilevel solvers. As a demonstration of the scalability of our multifluid
simulation capabilities we present an example weak scaling study. This example is for a fully-ionized
ion/electron high density/pressure core expanding into a magnetized background ion/electron
plasma and the simulations were run on the LANL Trinity machine on &gt; 16,000 cores.</p>
<p><img src="../img/gallery/drekar/3D_Cloud_expansion_scaling.png" alt="" width="100%">
<em>Illustration of weak scaling for implicit fully-ionized multifluid plasma model (electrons, ions) for the simulation of an 3D high density/pressure
cloud expanding in a lower density background plasma with anisotropic expansion due to the presence of a magnetic field. Multiphysics block preconditioning
methods are used to provide a scalable solution in parallel on the Los Alamos Trinity machine.</em></p>
<p>The physics simulation goal is to understand impurity penetration and assimilation into plasmas for proposed disruption
mitigation techniques. These techniques currently include massive gas injection and frozen pellet injection.
To computationally simulate the proposed type of problems requires robust, accurate and
scalable plasma modeling capabilities. We have completed an initial development of a general
capability for partially-ionized plasmas composed of multiple atomic species with strongly driven multidimensional
hydrodynamic transport processes, collisional, ionization and recombination interactions,
and strong coupling to electric and magnetic fields.</p>
<script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: {equationNumbers: {autoNumber: "all"}}, tex2jax: {inlineMath: [['$','$']]}});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_HTML"></script></div>
            <div class="col-md-3 hidden-xs hidden-sm"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#high-performance-parallel-scaling-of-fluid-plasma-simulations-in-drekar">High performance parallel scaling of fluid plasma simulations in Drekar</a></li>
        
            <li><a href="#overview">Overview</a></li>
        
            <li><a href="#scaling-of-multilevel-preconditioners-for-resistive-mhd-based-on-multiphysics-block-preconditioning-preliminary-results">Scaling of Multilevel Preconditioners for resistive MHD based on multiphysics block preconditioning (preliminary results)</a></li>
        
            <li><a href="#scalable-multilfuid-em-solvers-based-on-multiphysics-block-preconditioning">Scalable multilfuid EM solvers based on multiphysics block preconditioning</a></li>
        
    
    </ul>
</div>

<!-- Developer notes:
  See the MkDocs documentation in https://www.mkdocs.org/dev-guide/themes/#page
  and the Jinja2 template API in https://tedboy.github.io/jinja2/index.html
--></div>
            
        </div>

        <footer class="footer">
           <div class="container">
               <p class="text-muted alignright">Approved for public release; distribution is unlimited.</p>
              <p class="text-muted alignleft">
                  Developed by the <a href="/about/">TDS team</a> at
                  <a href="https://www.lanl.gov/">LANL</a> based on
                  <a href="https://mfem.org/">MFEM</a> webpage template.</p>
           </div>
        </footer>
        
        <script src="../js/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/highlight.pack.js"></script>
        <script src="../js/base.js"></script>
        <script src="../js/retina.min.js"></script>
        <!-- <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script> --> <!-- file missing in repo -->
        <script src="../search/main.js"></script>
    </body>
</html>